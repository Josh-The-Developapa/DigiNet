{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Neural Network\n",
    "\n",
    "We build a multi-class classification ANN (Artificial Neural Network) that we'll train to predict the true values of hand-written digits from the famous **MNIST** database\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our dataset\n",
    "\n",
    "We load data from the famous MNIST dataset for handwritten digits for numbers 0-9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Training data\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True,\n",
    "    target_transform=transforms.Lambda(\n",
    "        lambda y: torch.zeros(10, dtype=torch.float).scatter_(\n",
    "            dim=0, index=torch.tensor(y), value=1\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "# Testing data\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True,\n",
    "    # Convert our labels from scalars to 0 filled tensors with a 1 at the index of the value of our label\n",
    "    # i.e tensor(5) -> tensor([0,0,0,0,0,1,0,0,0,0])\n",
    "    target_transform=transforms.Lambda(\n",
    "        lambda y: torch.zeros(10, dtype=torch.float).scatter_(\n",
    "            dim=0, index=torch.tensor(y), value=1\n",
    "        )\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's visualise our data using `matplotlib`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_mnist(dataset, num_images):\n",
    "    # Get the first 'num_images' samples from the dataset\n",
    "    images = dataset.data[:num_images]\n",
    "    labels = dataset.targets[:num_images]\n",
    "\n",
    "    # Create a grid of subplots to display the images\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(10, 3))\n",
    "\n",
    "    for i, (image, label) in enumerate(zip(images, labels)):\n",
    "        # Plot the image on the corresponding subplot\n",
    "        axes[i].imshow(image, cmap=\"gray\")\n",
    "        axes[i].set_title(f\"Batch: {i} | Label: {label}\")\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    # Adjust spacing between subplots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize the first 6 samples from the train dataset\n",
    "visualize_mnist(training_data, num_images=6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare our data for training with data loaders\n",
    "\n",
    "**Note**: Each batch in the dataloaders is a python list of 2 elements. The first element is a tensor of images of size (64,1,28,28). Meaning it is a 4D tensor containing 64 3D tensors of images. Now the second element of the batch is a tensor of labels. Each label is of size 10. So the overall shape of this tensor is (64,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64, 10])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "train_images = None\n",
    "train_labels = None\n",
    "\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    train_images = batch[0]\n",
    "    train_labels = batch[1]\n",
    "    break\n",
    "\n",
    "print(f\"Feature batch shape: {train_images.shape}\")\n",
    "print(f\"Labels batch shape: {train_labels.shape}\")\n",
    "\n",
    "# Get the first image tensor and its corresponding label of the first batch\n",
    "img = train_images[0].squeeze()\n",
    "label = train_labels[0]\n",
    "\n",
    "# Get the value of the label using index of the 1 value\n",
    "index = torch.where(label == 1)[0].item()\n",
    "\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title(f\"Label: {label}\\n Number: {index}\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make our Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigiNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DigiNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(784, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# Instantiate our model\n",
    "model = DigiNet()\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Define our loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define our optimiser\n",
    "optimiser = optim.SGD(params=model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train our Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch: 0\n",
      " --------------------\n",
      "Loss: 2.3087430000305176 | 0/938\n",
      "Loss: 2.2531189918518066 | 100/938\n",
      "Loss: 2.2042288780212402 | 200/938\n",
      "Loss: 2.0047638416290283 | 300/938\n",
      "Loss: 1.8490183353424072 | 400/938\n",
      "Loss: 1.5599956512451172 | 500/938\n",
      "Loss: 1.1450539827346802 | 600/938\n",
      "Loss: 1.1097042560577393 | 700/938\n",
      "Loss: 0.8500213623046875 | 800/938\n",
      "Loss: 0.7079877853393555 | 900/938\n",
      "\n",
      " Epoch: 1\n",
      " --------------------\n",
      "Loss: 0.7482163310050964 | 0/938\n",
      "Loss: 0.5544400215148926 | 100/938\n",
      "Loss: 0.5325507521629333 | 200/938\n",
      "Loss: 0.5379599332809448 | 300/938\n",
      "Loss: 0.45656007528305054 | 400/938\n",
      "Loss: 0.4619792401790619 | 500/938\n",
      "Loss: 0.33756816387176514 | 600/938\n",
      "Loss: 0.5305097103118896 | 700/938\n",
      "Loss: 0.47179245948791504 | 800/938\n",
      "Loss: 0.4680901765823364 | 900/938\n",
      "\n",
      " Epoch: 2\n",
      " --------------------\n",
      "Loss: 0.42974111437797546 | 0/938\n",
      "Loss: 0.328075110912323 | 100/938\n",
      "Loss: 0.31777423620224 | 200/938\n",
      "Loss: 0.4117664694786072 | 300/938\n",
      "Loss: 0.31257984042167664 | 400/938\n",
      "Loss: 0.378135621547699 | 500/938\n",
      "Loss: 0.23920957744121552 | 600/938\n",
      "Loss: 0.44385695457458496 | 700/938\n",
      "Loss: 0.3933764100074768 | 800/938\n",
      "Loss: 0.4309641718864441 | 900/938\n",
      "\n",
      " Epoch: 3\n",
      " --------------------\n",
      "Loss: 0.3194392919540405 | 0/938\n",
      "Loss: 0.28496113419532776 | 100/938\n",
      "Loss: 0.24499642848968506 | 200/938\n",
      "Loss: 0.37434104084968567 | 300/938\n",
      "Loss: 0.2646801471710205 | 400/938\n",
      "Loss: 0.3424011468887329 | 500/938\n",
      "Loss: 0.20432402193546295 | 600/938\n",
      "Loss: 0.4011073410511017 | 700/938\n",
      "Loss: 0.34676671028137207 | 800/938\n",
      "Loss: 0.4074126183986664 | 900/938\n",
      "\n",
      " Epoch: 4\n",
      " --------------------\n",
      "Loss: 0.2621610164642334 | 0/938\n",
      "Loss: 0.26742956042289734 | 100/938\n",
      "Loss: 0.20634838938713074 | 200/938\n",
      "Loss: 0.35312485694885254 | 300/938\n",
      "Loss: 0.23701626062393188 | 400/938\n",
      "Loss: 0.31981682777404785 | 500/938\n",
      "Loss: 0.1856168508529663 | 600/938\n",
      "Loss: 0.37301120162010193 | 700/938\n",
      "Loss: 0.30792370438575745 | 800/938\n",
      "Loss: 0.385249525308609 | 900/938\n",
      "\n",
      " Epoch: 5\n",
      " --------------------\n",
      "Loss: 0.2242632359266281 | 0/938\n",
      "Loss: 0.2541429400444031 | 100/938\n",
      "Loss: 0.18238286674022675 | 200/938\n",
      "Loss: 0.3371056914329529 | 300/938\n",
      "Loss: 0.21601325273513794 | 400/938\n",
      "Loss: 0.30210357904434204 | 500/938\n",
      "Loss: 0.17113183438777924 | 600/938\n",
      "Loss: 0.35245075821876526 | 700/938\n",
      "Loss: 0.27332764863967896 | 800/938\n",
      "Loss: 0.36239394545555115 | 900/938\n",
      "\n",
      " Epoch: 6\n",
      " --------------------\n",
      "Loss: 0.1968001276254654 | 0/938\n",
      "Loss: 0.24051891267299652 | 100/938\n",
      "Loss: 0.16525483131408691 | 200/938\n",
      "Loss: 0.321762353181839 | 300/938\n",
      "Loss: 0.1984785497188568 | 400/938\n",
      "Loss: 0.2882312834262848 | 500/938\n",
      "Loss: 0.1584693193435669 | 600/938\n",
      "Loss: 0.3351854085922241 | 700/938\n",
      "Loss: 0.243195042014122 | 800/938\n",
      "Loss: 0.3408753573894501 | 900/938\n",
      "\n",
      " Epoch: 7\n",
      " --------------------\n",
      "Loss: 0.17530891299247742 | 0/938\n",
      "Loss: 0.22782884538173676 | 100/938\n",
      "Loss: 0.15153095126152039 | 200/938\n",
      "Loss: 0.3066547214984894 | 300/938\n",
      "Loss: 0.18284523487091064 | 400/938\n",
      "Loss: 0.2764211595058441 | 500/938\n",
      "Loss: 0.14638961851596832 | 600/938\n",
      "Loss: 0.3182692527770996 | 700/938\n",
      "Loss: 0.21827144920825958 | 800/938\n",
      "Loss: 0.32068440318107605 | 900/938\n",
      "\n",
      " Epoch: 8\n",
      " --------------------\n",
      "Loss: 0.15790845453739166 | 0/938\n",
      "Loss: 0.21605312824249268 | 100/938\n",
      "Loss: 0.14030058681964874 | 200/938\n",
      "Loss: 0.29258808493614197 | 300/938\n",
      "Loss: 0.16918064653873444 | 400/938\n",
      "Loss: 0.26704174280166626 | 500/938\n",
      "Loss: 0.13488665223121643 | 600/938\n",
      "Loss: 0.3035562336444855 | 700/938\n",
      "Loss: 0.1980971395969391 | 800/938\n",
      "Loss: 0.30262070894241333 | 900/938\n",
      "\n",
      " Epoch: 9\n",
      " --------------------\n",
      "Loss: 0.1428637057542801 | 0/938\n",
      "Loss: 0.2057001143693924 | 100/938\n",
      "Loss: 0.1302562803030014 | 200/938\n",
      "Loss: 0.2800157070159912 | 300/938\n",
      "Loss: 0.15712280571460724 | 400/938\n",
      "Loss: 0.25864818692207336 | 500/938\n",
      "Loss: 0.12476851046085358 | 600/938\n",
      "Loss: 0.29038915038108826 | 700/938\n",
      "Loss: 0.18234868347644806 | 800/938\n",
      "Loss: 0.2865082919597626 | 900/938\n",
      "\n",
      " Epoch: 10\n",
      " --------------------\n",
      "Loss: 0.13002702593803406 | 0/938\n",
      "Loss: 0.19592207670211792 | 100/938\n",
      "Loss: 0.12174797803163528 | 200/938\n",
      "Loss: 0.26785361766815186 | 300/938\n",
      "Loss: 0.14614146947860718 | 400/938\n",
      "Loss: 0.24953746795654297 | 500/938\n",
      "Loss: 0.1156669333577156 | 600/938\n",
      "Loss: 0.27767083048820496 | 700/938\n",
      "Loss: 0.17027758061885834 | 800/938\n",
      "Loss: 0.2720695734024048 | 900/938\n",
      "\n",
      " Epoch: 11\n",
      " --------------------\n",
      "Loss: 0.11903025954961777 | 0/938\n",
      "Loss: 0.1870938390493393 | 100/938\n",
      "Loss: 0.1142088770866394 | 200/938\n",
      "Loss: 0.25672122836112976 | 300/938\n",
      "Loss: 0.13659624755382538 | 400/938\n",
      "Loss: 0.24131375551223755 | 500/938\n",
      "Loss: 0.10745517164468765 | 600/938\n",
      "Loss: 0.26578375697135925 | 700/938\n",
      "Loss: 0.16119492053985596 | 800/938\n",
      "Loss: 0.25931069254875183 | 900/938\n",
      "\n",
      " Epoch: 12\n",
      " --------------------\n",
      "Loss: 0.10969587415456772 | 0/938\n",
      "Loss: 0.1793372631072998 | 100/938\n",
      "Loss: 0.10720940679311752 | 200/938\n",
      "Loss: 0.24597571790218353 | 300/938\n",
      "Loss: 0.12810611724853516 | 400/938\n",
      "Loss: 0.23382066190242767 | 500/938\n",
      "Loss: 0.1002793237566948 | 600/938\n",
      "Loss: 0.2553759515285492 | 700/938\n",
      "Loss: 0.1538410633802414 | 800/938\n",
      "Loss: 0.2480529397726059 | 900/938\n",
      "\n",
      " Epoch: 13\n",
      " --------------------\n",
      "Loss: 0.10135452449321747 | 0/938\n",
      "Loss: 0.17242619395256042 | 100/938\n",
      "Loss: 0.10107403248548508 | 200/938\n",
      "Loss: 0.23572582006454468 | 300/938\n",
      "Loss: 0.12050031870603561 | 400/938\n",
      "Loss: 0.22605951130390167 | 500/938\n",
      "Loss: 0.09420491755008698 | 600/938\n",
      "Loss: 0.24549169838428497 | 700/938\n",
      "Loss: 0.14741553366184235 | 800/938\n",
      "Loss: 0.23821566998958588 | 900/938\n",
      "\n",
      " Epoch: 14\n",
      " --------------------\n",
      "Loss: 0.09380533546209335 | 0/938\n",
      "Loss: 0.16626010835170746 | 100/938\n",
      "Loss: 0.0957246646285057 | 200/938\n",
      "Loss: 0.22536450624465942 | 300/938\n",
      "Loss: 0.11365247517824173 | 400/938\n",
      "Loss: 0.21808433532714844 | 500/938\n",
      "Loss: 0.08892673254013062 | 600/938\n",
      "Loss: 0.2360568791627884 | 700/938\n",
      "Loss: 0.1414259374141693 | 800/938\n",
      "Loss: 0.22962772846221924 | 900/938\n",
      "\n",
      " Epoch: 15\n",
      " --------------------\n",
      "Loss: 0.08729777485132217 | 0/938\n",
      "Loss: 0.1602833867073059 | 100/938\n",
      "Loss: 0.09116800874471664 | 200/938\n",
      "Loss: 0.21496905386447906 | 300/938\n",
      "Loss: 0.1075238287448883 | 400/938\n",
      "Loss: 0.20987354218959808 | 500/938\n",
      "Loss: 0.08408024162054062 | 600/938\n",
      "Loss: 0.2270861268043518 | 700/938\n",
      "Loss: 0.13604694604873657 | 800/938\n",
      "Loss: 0.22166354954242706 | 900/938\n",
      "\n",
      " Epoch: 16\n",
      " --------------------\n",
      "Loss: 0.08147892355918884 | 0/938\n",
      "Loss: 0.15487700700759888 | 100/938\n",
      "Loss: 0.08743666857481003 | 200/938\n",
      "Loss: 0.20552006363868713 | 300/938\n",
      "Loss: 0.10202796012163162 | 400/938\n",
      "Loss: 0.20118004083633423 | 500/938\n",
      "Loss: 0.07982910424470901 | 600/938\n",
      "Loss: 0.21963131427764893 | 700/938\n",
      "Loss: 0.13155227899551392 | 800/938\n",
      "Loss: 0.21419177949428558 | 900/938\n",
      "\n",
      " Epoch: 17\n",
      " --------------------\n",
      "Loss: 0.07592705637216568 | 0/938\n",
      "Loss: 0.15031172335147858 | 100/938\n",
      "Loss: 0.0839683786034584 | 200/938\n",
      "Loss: 0.19648128747940063 | 300/938\n",
      "Loss: 0.09732553362846375 | 400/938\n",
      "Loss: 0.19277895987033844 | 500/938\n",
      "Loss: 0.07584352791309357 | 600/938\n",
      "Loss: 0.21225710213184357 | 700/938\n",
      "Loss: 0.12684206664562225 | 800/938\n",
      "Loss: 0.20693692564964294 | 900/938\n",
      "\n",
      " Epoch: 18\n",
      " --------------------\n",
      "Loss: 0.07118924707174301 | 0/938\n",
      "Loss: 0.14586985111236572 | 100/938\n",
      "Loss: 0.08071139454841614 | 200/938\n",
      "Loss: 0.18800584971904755 | 300/938\n",
      "Loss: 0.09304384887218475 | 400/938\n",
      "Loss: 0.18492640554904938 | 500/938\n",
      "Loss: 0.07247884571552277 | 600/938\n",
      "Loss: 0.20500171184539795 | 700/938\n",
      "Loss: 0.12287362664937973 | 800/938\n",
      "Loss: 0.20055416226387024 | 900/938\n",
      "\n",
      " Epoch: 19\n",
      " --------------------\n",
      "Loss: 0.06698834896087646 | 0/938\n",
      "Loss: 0.14124153554439545 | 100/938\n",
      "Loss: 0.07790588587522507 | 200/938\n",
      "Loss: 0.18007872998714447 | 300/938\n",
      "Loss: 0.08918017894029617 | 400/938\n",
      "Loss: 0.17743277549743652 | 500/938\n",
      "Loss: 0.06942909210920334 | 600/938\n",
      "Loss: 0.1981089860200882 | 700/938\n",
      "Loss: 0.11910402774810791 | 800/938\n",
      "Loss: 0.19477961957454681 | 900/938\n",
      "\n",
      " Epoch: 20\n",
      " --------------------\n",
      "Loss: 0.06305775046348572 | 0/938\n",
      "Loss: 0.13741891086101532 | 100/938\n",
      "Loss: 0.07552997022867203 | 200/938\n",
      "Loss: 0.17241859436035156 | 300/938\n",
      "Loss: 0.08546402305364609 | 400/938\n",
      "Loss: 0.16937963664531708 | 500/938\n",
      "Loss: 0.06670927256345749 | 600/938\n",
      "Loss: 0.19117774069309235 | 700/938\n",
      "Loss: 0.11574427783489227 | 800/938\n",
      "Loss: 0.18918299674987793 | 900/938\n",
      "\n",
      " Epoch: 21\n",
      " --------------------\n",
      "Loss: 0.05955282598733902 | 0/938\n",
      "Loss: 0.13406512141227722 | 100/938\n",
      "Loss: 0.0735892653465271 | 200/938\n",
      "Loss: 0.1648179292678833 | 300/938\n",
      "Loss: 0.08209769427776337 | 400/938\n",
      "Loss: 0.16239069402217865 | 500/938\n",
      "Loss: 0.06439071148633957 | 600/938\n",
      "Loss: 0.18445619940757751 | 700/938\n",
      "Loss: 0.11262580752372742 | 800/938\n",
      "Loss: 0.18373562395572662 | 900/938\n",
      "\n",
      " Epoch: 22\n",
      " --------------------\n",
      "Loss: 0.05612902715802193 | 0/938\n",
      "Loss: 0.13070692121982574 | 100/938\n",
      "Loss: 0.07179950177669525 | 200/938\n",
      "Loss: 0.15808339416980743 | 300/938\n",
      "Loss: 0.07908602058887482 | 400/938\n",
      "Loss: 0.15568552911281586 | 500/938\n",
      "Loss: 0.06226276233792305 | 600/938\n",
      "Loss: 0.17842958867549896 | 700/938\n",
      "Loss: 0.10967187583446503 | 800/938\n",
      "Loss: 0.17873349785804749 | 900/938\n",
      "\n",
      " Epoch: 23\n",
      " --------------------\n",
      "Loss: 0.05295296013355255 | 0/938\n",
      "Loss: 0.1274137794971466 | 100/938\n",
      "Loss: 0.0700250118970871 | 200/938\n",
      "Loss: 0.15171758830547333 | 300/938\n",
      "Loss: 0.07605286687612534 | 400/938\n",
      "Loss: 0.14878617227077484 | 500/938\n",
      "Loss: 0.06025267392396927 | 600/938\n",
      "Loss: 0.17216061055660248 | 700/938\n",
      "Loss: 0.10712654888629913 | 800/938\n",
      "Loss: 0.17392446100711823 | 900/938\n",
      "\n",
      " Epoch: 24\n",
      " --------------------\n",
      "Loss: 0.05006437003612518 | 0/938\n",
      "Loss: 0.12404341250658035 | 100/938\n",
      "Loss: 0.06843379884958267 | 200/938\n",
      "Loss: 0.14599023759365082 | 300/938\n",
      "Loss: 0.07293424755334854 | 400/938\n",
      "Loss: 0.14227283000946045 | 500/938\n",
      "Loss: 0.05838660150766373 | 600/938\n",
      "Loss: 0.16592931747436523 | 700/938\n",
      "Loss: 0.10460661351680756 | 800/938\n",
      "Loss: 0.16926813125610352 | 900/938\n",
      "\n",
      " Epoch: 25\n",
      " --------------------\n",
      "Loss: 0.04746812582015991 | 0/938\n",
      "Loss: 0.12115591019392014 | 100/938\n",
      "Loss: 0.06697618961334229 | 200/938\n",
      "Loss: 0.14082945883274078 | 300/938\n",
      "Loss: 0.06991642713546753 | 400/938\n",
      "Loss: 0.1362420618534088 | 500/938\n",
      "Loss: 0.05664519965648651 | 600/938\n",
      "Loss: 0.1602032631635666 | 700/938\n",
      "Loss: 0.10215841978788376 | 800/938\n",
      "Loss: 0.16471248865127563 | 900/938\n",
      "\n",
      " Epoch: 26\n",
      " --------------------\n",
      "Loss: 0.045097604393959045 | 0/938\n",
      "Loss: 0.11774932593107224 | 100/938\n",
      "Loss: 0.06574618816375732 | 200/938\n",
      "Loss: 0.13595691323280334 | 300/938\n",
      "Loss: 0.06689469516277313 | 400/938\n",
      "Loss: 0.13083812594413757 | 500/938\n",
      "Loss: 0.05509990453720093 | 600/938\n",
      "Loss: 0.1544741839170456 | 700/938\n",
      "Loss: 0.10017780214548111 | 800/938\n",
      "Loss: 0.16063827276229858 | 900/938\n",
      "\n",
      " Epoch: 27\n",
      " --------------------\n",
      "Loss: 0.042726851999759674 | 0/938\n",
      "Loss: 0.11453630775213242 | 100/938\n",
      "Loss: 0.06459120661020279 | 200/938\n",
      "Loss: 0.13114987313747406 | 300/938\n",
      "Loss: 0.06409310549497604 | 400/938\n",
      "Loss: 0.12521764636039734 | 500/938\n",
      "Loss: 0.053649596869945526 | 600/938\n",
      "Loss: 0.14893566071987152 | 700/938\n",
      "Loss: 0.09822799265384674 | 800/938\n",
      "Loss: 0.15697966516017914 | 900/938\n",
      "\n",
      " Epoch: 28\n",
      " --------------------\n",
      "Loss: 0.04056055471301079 | 0/938\n",
      "Loss: 0.11147250980138779 | 100/938\n",
      "Loss: 0.0635874941945076 | 200/938\n",
      "Loss: 0.12676295638084412 | 300/938\n",
      "Loss: 0.06115125119686127 | 400/938\n",
      "Loss: 0.11972497403621674 | 500/938\n",
      "Loss: 0.05231918394565582 | 600/938\n",
      "Loss: 0.143528014421463 | 700/938\n",
      "Loss: 0.096212238073349 | 800/938\n",
      "Loss: 0.15317527949810028 | 900/938\n",
      "\n",
      " Epoch: 29\n",
      " --------------------\n",
      "Loss: 0.03868494927883148 | 0/938\n",
      "Loss: 0.1084171012043953 | 100/938\n",
      "Loss: 0.06256145238876343 | 200/938\n",
      "Loss: 0.12257439643144608 | 300/938\n",
      "Loss: 0.05838702246546745 | 400/938\n",
      "Loss: 0.11449325084686279 | 500/938\n",
      "Loss: 0.05097174644470215 | 600/938\n",
      "Loss: 0.13851766288280487 | 700/938\n",
      "Loss: 0.09432018548250198 | 800/938\n",
      "Loss: 0.1491411328315735 | 900/938\n",
      "\n",
      " Epoch: 30\n",
      " --------------------\n",
      "Loss: 0.03701408579945564 | 0/938\n",
      "Loss: 0.10553991794586182 | 100/938\n",
      "Loss: 0.06154773384332657 | 200/938\n",
      "Loss: 0.11799848079681396 | 300/938\n",
      "Loss: 0.05582444742321968 | 400/938\n",
      "Loss: 0.10961075127124786 | 500/938\n",
      "Loss: 0.04990091547369957 | 600/938\n",
      "Loss: 0.13364669680595398 | 700/938\n",
      "Loss: 0.09272684156894684 | 800/938\n",
      "Loss: 0.14563660323619843 | 900/938\n",
      "\n",
      " Epoch: 31\n",
      " --------------------\n",
      "Loss: 0.03546998277306557 | 0/938\n",
      "Loss: 0.10258163511753082 | 100/938\n",
      "Loss: 0.06070271134376526 | 200/938\n",
      "Loss: 0.11331022530794144 | 300/938\n",
      "Loss: 0.05324673280119896 | 400/938\n",
      "Loss: 0.10497255623340607 | 500/938\n",
      "Loss: 0.048800382763147354 | 600/938\n",
      "Loss: 0.12896297872066498 | 700/938\n",
      "Loss: 0.09118764847517014 | 800/938\n",
      "Loss: 0.14187872409820557 | 900/938\n",
      "\n",
      " Epoch: 32\n",
      " --------------------\n",
      "Loss: 0.034096609801054 | 0/938\n",
      "Loss: 0.09964005649089813 | 100/938\n",
      "Loss: 0.05998866260051727 | 200/938\n",
      "Loss: 0.10903976857662201 | 300/938\n",
      "Loss: 0.050632886588573456 | 400/938\n",
      "Loss: 0.10002058744430542 | 500/938\n",
      "Loss: 0.04766199365258217 | 600/938\n",
      "Loss: 0.12421994656324387 | 700/938\n",
      "Loss: 0.08965907990932465 | 800/938\n",
      "Loss: 0.1383891999721527 | 900/938\n",
      "\n",
      " Epoch: 33\n",
      " --------------------\n",
      "Loss: 0.032842766493558884 | 0/938\n",
      "Loss: 0.09670692682266235 | 100/938\n",
      "Loss: 0.05922301486134529 | 200/938\n",
      "Loss: 0.10444940626621246 | 300/938\n",
      "Loss: 0.04813946783542633 | 400/938\n",
      "Loss: 0.09560932219028473 | 500/938\n",
      "Loss: 0.046646274626255035 | 600/938\n",
      "Loss: 0.1197463870048523 | 700/938\n",
      "Loss: 0.08806627988815308 | 800/938\n",
      "Loss: 0.13467508554458618 | 900/938\n",
      "\n",
      " Epoch: 34\n",
      " --------------------\n",
      "Loss: 0.03169162571430206 | 0/938\n",
      "Loss: 0.09348245710134506 | 100/938\n",
      "Loss: 0.058456383645534515 | 200/938\n",
      "Loss: 0.10011152923107147 | 300/938\n",
      "Loss: 0.045483797788619995 | 400/938\n",
      "Loss: 0.09132368862628937 | 500/938\n",
      "Loss: 0.04554656520485878 | 600/938\n",
      "Loss: 0.11545634269714355 | 700/938\n",
      "Loss: 0.08678868412971497 | 800/938\n",
      "Loss: 0.1309136599302292 | 900/938\n",
      "\n",
      " Epoch: 35\n",
      " --------------------\n",
      "Loss: 0.030589034780859947 | 0/938\n",
      "Loss: 0.09056980162858963 | 100/938\n",
      "Loss: 0.05764568969607353 | 200/938\n",
      "Loss: 0.09582636505365372 | 300/938\n",
      "Loss: 0.04295000806450844 | 400/938\n",
      "Loss: 0.08723074942827225 | 500/938\n",
      "Loss: 0.04451529681682587 | 600/938\n",
      "Loss: 0.11145558208227158 | 700/938\n",
      "Loss: 0.08527518808841705 | 800/938\n",
      "Loss: 0.12734881043434143 | 900/938\n",
      "\n",
      " Epoch: 36\n",
      " --------------------\n",
      "Loss: 0.0296184029430151 | 0/938\n",
      "Loss: 0.08776779472827911 | 100/938\n",
      "Loss: 0.0569789856672287 | 200/938\n",
      "Loss: 0.09170202910900116 | 300/938\n",
      "Loss: 0.040358565747737885 | 400/938\n",
      "Loss: 0.08355823904275894 | 500/938\n",
      "Loss: 0.0435187853872776 | 600/938\n",
      "Loss: 0.10771747678518295 | 700/938\n",
      "Loss: 0.08440279960632324 | 800/938\n",
      "Loss: 0.1240929514169693 | 900/938\n",
      "\n",
      " Epoch: 37\n",
      " --------------------\n",
      "Loss: 0.028790926560759544 | 0/938\n",
      "Loss: 0.085227832198143 | 100/938\n",
      "Loss: 0.056054841727018356 | 200/938\n",
      "Loss: 0.08731697499752045 | 300/938\n",
      "Loss: 0.0381159670650959 | 400/938\n",
      "Loss: 0.07970316708087921 | 500/938\n",
      "Loss: 0.04235297441482544 | 600/938\n",
      "Loss: 0.10403723269701004 | 700/938\n",
      "Loss: 0.08315494656562805 | 800/938\n",
      "Loss: 0.12037380784749985 | 900/938\n",
      "\n",
      " Epoch: 38\n",
      " --------------------\n",
      "Loss: 0.027976354584097862 | 0/938\n",
      "Loss: 0.08255935460329056 | 100/938\n",
      "Loss: 0.05538250505924225 | 200/938\n",
      "Loss: 0.08287984877824783 | 300/938\n",
      "Loss: 0.0360226146876812 | 400/938\n",
      "Loss: 0.07586806267499924 | 500/938\n",
      "Loss: 0.041329819709062576 | 600/938\n",
      "Loss: 0.10018960386514664 | 700/938\n",
      "Loss: 0.08183105289936066 | 800/938\n",
      "Loss: 0.1167481392621994 | 900/938\n",
      "\n",
      " Epoch: 39\n",
      " --------------------\n",
      "Loss: 0.02728785201907158 | 0/938\n",
      "Loss: 0.0800095722079277 | 100/938\n",
      "Loss: 0.05457337200641632 | 200/938\n",
      "Loss: 0.078704334795475 | 300/938\n",
      "Loss: 0.0341465063393116 | 400/938\n",
      "Loss: 0.07249916344881058 | 500/938\n",
      "Loss: 0.04022674635052681 | 600/938\n",
      "Loss: 0.09628301858901978 | 700/938\n",
      "Loss: 0.08072537183761597 | 800/938\n",
      "Loss: 0.11337799578905106 | 900/938\n",
      "\n",
      " Epoch: 40\n",
      " --------------------\n",
      "Loss: 0.026573987677693367 | 0/938\n",
      "Loss: 0.07767951488494873 | 100/938\n",
      "Loss: 0.05367647483944893 | 200/938\n",
      "Loss: 0.07440660148859024 | 300/938\n",
      "Loss: 0.03232709318399429 | 400/938\n",
      "Loss: 0.06905502825975418 | 500/938\n",
      "Loss: 0.0391455814242363 | 600/938\n",
      "Loss: 0.09241382032632828 | 700/938\n",
      "Loss: 0.0794248878955841 | 800/938\n",
      "Loss: 0.10983166098594666 | 900/938\n",
      "\n",
      " Epoch: 41\n",
      " --------------------\n",
      "Loss: 0.02605311945080757 | 0/938\n",
      "Loss: 0.07532154768705368 | 100/938\n",
      "Loss: 0.052952565252780914 | 200/938\n",
      "Loss: 0.07034709304571152 | 300/938\n",
      "Loss: 0.030731717124581337 | 400/938\n",
      "Loss: 0.06581522524356842 | 500/938\n",
      "Loss: 0.03801274672150612 | 600/938\n",
      "Loss: 0.08880680054426193 | 700/938\n",
      "Loss: 0.07820894569158554 | 800/938\n",
      "Loss: 0.10664278268814087 | 900/938\n",
      "\n",
      " Epoch: 42\n",
      " --------------------\n",
      "Loss: 0.02555316500365734 | 0/938\n",
      "Loss: 0.07304294407367706 | 100/938\n",
      "Loss: 0.05201996862888336 | 200/938\n",
      "Loss: 0.06587926298379898 | 300/938\n",
      "Loss: 0.029279764741659164 | 400/938\n",
      "Loss: 0.06263493746519089 | 500/938\n",
      "Loss: 0.03680047020316124 | 600/938\n",
      "Loss: 0.08522243797779083 | 700/938\n",
      "Loss: 0.07739677280187607 | 800/938\n",
      "Loss: 0.10320357978343964 | 900/938\n",
      "\n",
      " Epoch: 43\n",
      " --------------------\n",
      "Loss: 0.025040220469236374 | 0/938\n",
      "Loss: 0.07090238481760025 | 100/938\n",
      "Loss: 0.05112341046333313 | 200/938\n",
      "Loss: 0.06185457855463028 | 300/938\n",
      "Loss: 0.027721989899873734 | 400/938\n",
      "Loss: 0.059734515845775604 | 500/938\n",
      "Loss: 0.035694610327482224 | 600/938\n",
      "Loss: 0.08127710223197937 | 700/938\n",
      "Loss: 0.0764719694852829 | 800/938\n",
      "Loss: 0.10027603060007095 | 900/938\n",
      "\n",
      " Epoch: 44\n",
      " --------------------\n",
      "Loss: 0.02460154891014099 | 0/938\n",
      "Loss: 0.06858977675437927 | 100/938\n",
      "Loss: 0.05029256269335747 | 200/938\n",
      "Loss: 0.058075036853551865 | 300/938\n",
      "Loss: 0.02637629397213459 | 400/938\n",
      "Loss: 0.057122014462947845 | 500/938\n",
      "Loss: 0.03474637493491173 | 600/938\n",
      "Loss: 0.07769501209259033 | 700/938\n",
      "Loss: 0.0756649449467659 | 800/938\n",
      "Loss: 0.09723003953695297 | 900/938\n",
      "\n",
      " Epoch: 45\n",
      " --------------------\n",
      "Loss: 0.02409953996539116 | 0/938\n",
      "Loss: 0.06657908856868744 | 100/938\n",
      "Loss: 0.04944610595703125 | 200/938\n",
      "Loss: 0.054202768951654434 | 300/938\n",
      "Loss: 0.025095228105783463 | 400/938\n",
      "Loss: 0.05452252924442291 | 500/938\n",
      "Loss: 0.03360987827181816 | 600/938\n",
      "Loss: 0.07430092990398407 | 700/938\n",
      "Loss: 0.07468830049037933 | 800/938\n",
      "Loss: 0.09434960782527924 | 900/938\n",
      "\n",
      " Epoch: 46\n",
      " --------------------\n",
      "Loss: 0.02368299476802349 | 0/938\n",
      "Loss: 0.06478196382522583 | 100/938\n",
      "Loss: 0.04859846830368042 | 200/938\n",
      "Loss: 0.05068249627947807 | 300/938\n",
      "Loss: 0.023896872997283936 | 400/938\n",
      "Loss: 0.05220923572778702 | 500/938\n",
      "Loss: 0.032619405537843704 | 600/938\n",
      "Loss: 0.07095920294523239 | 700/938\n",
      "Loss: 0.07375375926494598 | 800/938\n",
      "Loss: 0.09168349206447601 | 900/938\n",
      "\n",
      " Epoch: 47\n",
      " --------------------\n",
      "Loss: 0.023352524265646935 | 0/938\n",
      "Loss: 0.06264514476060867 | 100/938\n",
      "Loss: 0.04759633541107178 | 200/938\n",
      "Loss: 0.04735054075717926 | 300/938\n",
      "Loss: 0.022895561531186104 | 400/938\n",
      "Loss: 0.05003407225012779 | 500/938\n",
      "Loss: 0.031463537365198135 | 600/938\n",
      "Loss: 0.06779580563306808 | 700/938\n",
      "Loss: 0.07319032400846481 | 800/938\n",
      "Loss: 0.08868185430765152 | 900/938\n",
      "\n",
      " Epoch: 48\n",
      " --------------------\n",
      "Loss: 0.022939162328839302 | 0/938\n",
      "Loss: 0.06051717698574066 | 100/938\n",
      "Loss: 0.04657881706953049 | 200/938\n",
      "Loss: 0.04368116706609726 | 300/938\n",
      "Loss: 0.021872563287615776 | 400/938\n",
      "Loss: 0.047802895307540894 | 500/938\n",
      "Loss: 0.03043431229889393 | 600/938\n",
      "Loss: 0.06457275152206421 | 700/938\n",
      "Loss: 0.07214801013469696 | 800/938\n",
      "Loss: 0.08560923486948013 | 900/938\n",
      "\n",
      " Epoch: 49\n",
      " --------------------\n",
      "Loss: 0.022634705528616905 | 0/938\n",
      "Loss: 0.058821726590394974 | 100/938\n",
      "Loss: 0.045684583485126495 | 200/938\n",
      "Loss: 0.04060497134923935 | 300/938\n",
      "Loss: 0.02094036340713501 | 400/938\n",
      "Loss: 0.04583724960684776 | 500/938\n",
      "Loss: 0.029417671263217926 | 600/938\n",
      "Loss: 0.061619825661182404 | 700/938\n",
      "Loss: 0.07144014537334442 | 800/938\n",
      "Loss: 0.08264698088169098 | 900/938\n",
      "\n",
      " Epoch: 50\n",
      " --------------------\n",
      "Loss: 0.02226915955543518 | 0/938\n",
      "Loss: 0.05702218785881996 | 100/938\n",
      "Loss: 0.04482682794332504 | 200/938\n",
      "Loss: 0.03787476196885109 | 300/938\n",
      "Loss: 0.020127475261688232 | 400/938\n",
      "Loss: 0.043965455144643784 | 500/938\n",
      "Loss: 0.02837928757071495 | 600/938\n",
      "Loss: 0.05875245854258537 | 700/938\n",
      "Loss: 0.07079069316387177 | 800/938\n",
      "Loss: 0.07968340069055557 | 900/938\n",
      "\n",
      " Epoch: 51\n",
      " --------------------\n",
      "Loss: 0.021973609924316406 | 0/938\n",
      "Loss: 0.05487915873527527 | 100/938\n",
      "Loss: 0.044002190232276917 | 200/938\n",
      "Loss: 0.0349915437400341 | 300/938\n",
      "Loss: 0.019323233515024185 | 400/938\n",
      "Loss: 0.04231075197458267 | 500/938\n",
      "Loss: 0.02737664431333542 | 600/938\n",
      "Loss: 0.05618998408317566 | 700/938\n",
      "Loss: 0.06988859921693802 | 800/938\n",
      "Loss: 0.07704418152570724 | 900/938\n",
      "\n",
      " Epoch: 52\n",
      " --------------------\n",
      "Loss: 0.021781381219625473 | 0/938\n",
      "Loss: 0.05315384641289711 | 100/938\n",
      "Loss: 0.04320520535111427 | 200/938\n",
      "Loss: 0.03298349305987358 | 300/938\n",
      "Loss: 0.01860273815691471 | 400/938\n",
      "Loss: 0.040689822286367416 | 500/938\n",
      "Loss: 0.026299279183149338 | 600/938\n",
      "Loss: 0.05363916978240013 | 700/938\n",
      "Loss: 0.06934070587158203 | 800/938\n",
      "Loss: 0.07414822280406952 | 900/938\n",
      "\n",
      " Epoch: 53\n",
      " --------------------\n",
      "Loss: 0.021539079025387764 | 0/938\n",
      "Loss: 0.05124276503920555 | 100/938\n",
      "Loss: 0.04233682155609131 | 200/938\n",
      "Loss: 0.030899643898010254 | 300/938\n",
      "Loss: 0.018076755106449127 | 400/938\n",
      "Loss: 0.03927101939916611 | 500/938\n",
      "Loss: 0.025294210761785507 | 600/938\n",
      "Loss: 0.051103778183460236 | 700/938\n",
      "Loss: 0.06840986013412476 | 800/938\n",
      "Loss: 0.07137049734592438 | 900/938\n",
      "\n",
      " Epoch: 54\n",
      " --------------------\n",
      "Loss: 0.02129198983311653 | 0/938\n",
      "Loss: 0.049546532332897186 | 100/938\n",
      "Loss: 0.041547276079654694 | 200/938\n",
      "Loss: 0.029128234833478928 | 300/938\n",
      "Loss: 0.017344508320093155 | 400/938\n",
      "Loss: 0.03750147297978401 | 500/938\n",
      "Loss: 0.024436872452497482 | 600/938\n",
      "Loss: 0.04894828051328659 | 700/938\n",
      "Loss: 0.06773924827575684 | 800/938\n",
      "Loss: 0.06867816299200058 | 900/938\n",
      "\n",
      " Epoch: 55\n",
      " --------------------\n",
      "Loss: 0.020999988541007042 | 0/938\n",
      "Loss: 0.04763924330472946 | 100/938\n",
      "Loss: 0.040705420076847076 | 200/938\n",
      "Loss: 0.027507135644555092 | 300/938\n",
      "Loss: 0.016887329518795013 | 400/938\n",
      "Loss: 0.03623238205909729 | 500/938\n",
      "Loss: 0.02352851629257202 | 600/938\n",
      "Loss: 0.046639684587717056 | 700/938\n",
      "Loss: 0.06683340668678284 | 800/938\n",
      "Loss: 0.06580506265163422 | 900/938\n",
      "\n",
      " Epoch: 56\n",
      " --------------------\n",
      "Loss: 0.02087327092885971 | 0/938\n",
      "Loss: 0.046310216188430786 | 100/938\n",
      "Loss: 0.04000379890203476 | 200/938\n",
      "Loss: 0.026144489645957947 | 300/938\n",
      "Loss: 0.016293760389089584 | 400/938\n",
      "Loss: 0.03491072356700897 | 500/938\n",
      "Loss: 0.022626616060733795 | 600/938\n",
      "Loss: 0.044469039887189865 | 700/938\n",
      "Loss: 0.06552428007125854 | 800/938\n",
      "Loss: 0.06318026781082153 | 900/938\n",
      "\n",
      " Epoch: 57\n",
      " --------------------\n",
      "Loss: 0.02072950452566147 | 0/938\n",
      "Loss: 0.04451004043221474 | 100/938\n",
      "Loss: 0.039206866174936295 | 200/938\n",
      "Loss: 0.025188736617565155 | 300/938\n",
      "Loss: 0.01580834574997425 | 400/938\n",
      "Loss: 0.03365392982959747 | 500/938\n",
      "Loss: 0.021776989102363586 | 600/938\n",
      "Loss: 0.04253115877509117 | 700/938\n",
      "Loss: 0.06447900831699371 | 800/938\n",
      "Loss: 0.06038540601730347 | 900/938\n",
      "\n",
      " Epoch: 58\n",
      " --------------------\n",
      "Loss: 0.020673317834734917 | 0/938\n",
      "Loss: 0.04280268773436546 | 100/938\n",
      "Loss: 0.03848530352115631 | 200/938\n",
      "Loss: 0.02398126944899559 | 300/938\n",
      "Loss: 0.015366870909929276 | 400/938\n",
      "Loss: 0.03249892219901085 | 500/938\n",
      "Loss: 0.020925262942910194 | 600/938\n",
      "Loss: 0.04064096137881279 | 700/938\n",
      "Loss: 0.06380357593297958 | 800/938\n",
      "Loss: 0.05774516612291336 | 900/938\n",
      "\n",
      " Epoch: 59\n",
      " --------------------\n",
      "Loss: 0.020442243665456772 | 0/938\n",
      "Loss: 0.04131925478577614 | 100/938\n",
      "Loss: 0.03772746026515961 | 200/938\n",
      "Loss: 0.02329386956989765 | 300/938\n",
      "Loss: 0.0148363271728158 | 400/938\n",
      "Loss: 0.03119119629263878 | 500/938\n",
      "Loss: 0.020159823819994926 | 600/938\n",
      "Loss: 0.03881524130702019 | 700/938\n",
      "Loss: 0.06244834512472153 | 800/938\n",
      "Loss: 0.05502552539110184 | 900/938\n",
      "\n",
      " Epoch: 60\n",
      " --------------------\n",
      "Loss: 0.020265301689505577 | 0/938\n",
      "Loss: 0.03973263502120972 | 100/938\n",
      "Loss: 0.03706255182623863 | 200/938\n",
      "Loss: 0.02239791676402092 | 300/938\n",
      "Loss: 0.014389706775546074 | 400/938\n",
      "Loss: 0.030026927590370178 | 500/938\n",
      "Loss: 0.019374871626496315 | 600/938\n",
      "Loss: 0.037081923335790634 | 700/938\n",
      "Loss: 0.061567943543195724 | 800/938\n",
      "Loss: 0.0526135079562664 | 900/938\n",
      "\n",
      " Epoch: 61\n",
      " --------------------\n",
      "Loss: 0.020064279437065125 | 0/938\n",
      "Loss: 0.038544174283742905 | 100/938\n",
      "Loss: 0.036387622356414795 | 200/938\n",
      "Loss: 0.021766193211078644 | 300/938\n",
      "Loss: 0.01398618333041668 | 400/938\n",
      "Loss: 0.02883930131793022 | 500/938\n",
      "Loss: 0.018551182001829147 | 600/938\n",
      "Loss: 0.03549237549304962 | 700/938\n",
      "Loss: 0.06037631258368492 | 800/938\n",
      "Loss: 0.05011728033423424 | 900/938\n",
      "\n",
      " Epoch: 62\n",
      " --------------------\n",
      "Loss: 0.01998530700802803 | 0/938\n",
      "Loss: 0.03664756938815117 | 100/938\n",
      "Loss: 0.0356932058930397 | 200/938\n",
      "Loss: 0.02101070061326027 | 300/938\n",
      "Loss: 0.013699679635465145 | 400/938\n",
      "Loss: 0.02783200889825821 | 500/938\n",
      "Loss: 0.017931459471583366 | 600/938\n",
      "Loss: 0.03395770862698555 | 700/938\n",
      "Loss: 0.0591941699385643 | 800/938\n",
      "Loss: 0.04774513468146324 | 900/938\n",
      "\n",
      " Epoch: 63\n",
      " --------------------\n",
      "Loss: 0.019712397828698158 | 0/938\n",
      "Loss: 0.035235919058322906 | 100/938\n",
      "Loss: 0.03509918972849846 | 200/938\n",
      "Loss: 0.020612874999642372 | 300/938\n",
      "Loss: 0.013239855878055096 | 400/938\n",
      "Loss: 0.026799935847520828 | 500/938\n",
      "Loss: 0.017184065654873848 | 600/938\n",
      "Loss: 0.03247664123773575 | 700/938\n",
      "Loss: 0.058004092425107956 | 800/938\n",
      "Loss: 0.04558791220188141 | 900/938\n",
      "\n",
      " Epoch: 64\n",
      " --------------------\n",
      "Loss: 0.019535021856427193 | 0/938\n",
      "Loss: 0.03376970812678337 | 100/938\n",
      "Loss: 0.034490812569856644 | 200/938\n",
      "Loss: 0.020112471655011177 | 300/938\n",
      "Loss: 0.01292050164192915 | 400/938\n",
      "Loss: 0.025888457894325256 | 500/938\n",
      "Loss: 0.016591627150774002 | 600/938\n",
      "Loss: 0.03125383332371712 | 700/938\n",
      "Loss: 0.057084642350673676 | 800/938\n",
      "Loss: 0.04349362477660179 | 900/938\n",
      "\n",
      " Epoch: 65\n",
      " --------------------\n",
      "Loss: 0.01935921236872673 | 0/938\n",
      "Loss: 0.0324212945997715 | 100/938\n",
      "Loss: 0.034044910222291946 | 200/938\n",
      "Loss: 0.019685285165905952 | 300/938\n",
      "Loss: 0.012637858279049397 | 400/938\n",
      "Loss: 0.02499266155064106 | 500/938\n",
      "Loss: 0.015865711495280266 | 600/938\n",
      "Loss: 0.03004075586795807 | 700/938\n",
      "Loss: 0.05607778578996658 | 800/938\n",
      "Loss: 0.041311923414468765 | 900/938\n",
      "\n",
      " Epoch: 66\n",
      " --------------------\n",
      "Loss: 0.019367627799510956 | 0/938\n",
      "Loss: 0.031115274876356125 | 100/938\n",
      "Loss: 0.03334817662835121 | 200/938\n",
      "Loss: 0.019213013350963593 | 300/938\n",
      "Loss: 0.012248768471181393 | 400/938\n",
      "Loss: 0.024042492732405663 | 500/938\n",
      "Loss: 0.015230552293360233 | 600/938\n",
      "Loss: 0.028961410745978355 | 700/938\n",
      "Loss: 0.0548124797642231 | 800/938\n",
      "Loss: 0.03913414105772972 | 900/938\n",
      "\n",
      " Epoch: 67\n",
      " --------------------\n",
      "Loss: 0.019183749333024025 | 0/938\n",
      "Loss: 0.02977725863456726 | 100/938\n",
      "Loss: 0.032892659306526184 | 200/938\n",
      "Loss: 0.018897630274295807 | 300/938\n",
      "Loss: 0.011939078569412231 | 400/938\n",
      "Loss: 0.023187529295682907 | 500/938\n",
      "Loss: 0.014645303599536419 | 600/938\n",
      "Loss: 0.027863910421729088 | 700/938\n",
      "Loss: 0.05372347682714462 | 800/938\n",
      "Loss: 0.037514179944992065 | 900/938\n",
      "\n",
      " Epoch: 68\n",
      " --------------------\n",
      "Loss: 0.01897195354104042 | 0/938\n",
      "Loss: 0.028462175279855728 | 100/938\n",
      "Loss: 0.03244908154010773 | 200/938\n",
      "Loss: 0.01864362508058548 | 300/938\n",
      "Loss: 0.011684643104672432 | 400/938\n",
      "Loss: 0.022349422797560692 | 500/938\n",
      "Loss: 0.014146081171929836 | 600/938\n",
      "Loss: 0.026864992454648018 | 700/938\n",
      "Loss: 0.05255484580993652 | 800/938\n",
      "Loss: 0.035598523914813995 | 900/938\n",
      "\n",
      " Epoch: 69\n",
      " --------------------\n",
      "Loss: 0.018941691145300865 | 0/938\n",
      "Loss: 0.02730555459856987 | 100/938\n",
      "Loss: 0.031926851719617844 | 200/938\n",
      "Loss: 0.018304629251360893 | 300/938\n",
      "Loss: 0.011408102698624134 | 400/938\n",
      "Loss: 0.02160785347223282 | 500/938\n",
      "Loss: 0.013639433309435844 | 600/938\n",
      "Loss: 0.02595711313188076 | 700/938\n",
      "Loss: 0.051854223012924194 | 800/938\n",
      "Loss: 0.033822622150182724 | 900/938\n",
      "\n",
      " Epoch: 70\n",
      " --------------------\n",
      "Loss: 0.01890014111995697 | 0/938\n",
      "Loss: 0.02646997757256031 | 100/938\n",
      "Loss: 0.03136302903294563 | 200/938\n",
      "Loss: 0.01804785057902336 | 300/938\n",
      "Loss: 0.01119469664990902 | 400/938\n",
      "Loss: 0.02086280845105648 | 500/938\n",
      "Loss: 0.013123012147843838 | 600/938\n",
      "Loss: 0.02510744519531727 | 700/938\n",
      "Loss: 0.05040115863084793 | 800/938\n",
      "Loss: 0.032245565205812454 | 900/938\n",
      "\n",
      " Epoch: 71\n",
      " --------------------\n",
      "Loss: 0.018631212413311005 | 0/938\n",
      "Loss: 0.02523910254240036 | 100/938\n",
      "Loss: 0.030912237241864204 | 200/938\n",
      "Loss: 0.017737319692969322 | 300/938\n",
      "Loss: 0.010870811529457569 | 400/938\n",
      "Loss: 0.020225508138537407 | 500/938\n",
      "Loss: 0.012690626084804535 | 600/938\n",
      "Loss: 0.024201970547437668 | 700/938\n",
      "Loss: 0.04981810972094536 | 800/938\n",
      "Loss: 0.03069721721112728 | 900/938\n",
      "\n",
      " Epoch: 72\n",
      " --------------------\n",
      "Loss: 0.018515270203351974 | 0/938\n",
      "Loss: 0.02435472421348095 | 100/938\n",
      "Loss: 0.03041031025350094 | 200/938\n",
      "Loss: 0.01763092167675495 | 300/938\n",
      "Loss: 0.010712776333093643 | 400/938\n",
      "Loss: 0.01941400021314621 | 500/938\n",
      "Loss: 0.012292805127799511 | 600/938\n",
      "Loss: 0.02344299480319023 | 700/938\n",
      "Loss: 0.04838358610868454 | 800/938\n",
      "Loss: 0.028927013278007507 | 900/938\n",
      "\n",
      " Epoch: 73\n",
      " --------------------\n",
      "Loss: 0.018387338146567345 | 0/938\n",
      "Loss: 0.02327861823141575 | 100/938\n",
      "Loss: 0.02978828363120556 | 200/938\n",
      "Loss: 0.01735425926744938 | 300/938\n",
      "Loss: 0.010464856401085854 | 400/938\n",
      "Loss: 0.018781675025820732 | 500/938\n",
      "Loss: 0.011860491707921028 | 600/938\n",
      "Loss: 0.022727716714143753 | 700/938\n",
      "Loss: 0.04733266681432724 | 800/938\n",
      "Loss: 0.027686500921845436 | 900/938\n",
      "\n",
      " Epoch: 74\n",
      " --------------------\n",
      "Loss: 0.018315037712454796 | 0/938\n",
      "Loss: 0.022596223279833794 | 100/938\n",
      "Loss: 0.029307780787348747 | 200/938\n",
      "Loss: 0.017008960247039795 | 300/938\n",
      "Loss: 0.010312898084521294 | 400/938\n",
      "Loss: 0.01821659691631794 | 500/938\n",
      "Loss: 0.011499338783323765 | 600/938\n",
      "Loss: 0.022045254707336426 | 700/938\n",
      "Loss: 0.04613150656223297 | 800/938\n",
      "Loss: 0.0262009184807539 | 900/938\n",
      "\n",
      " Epoch: 75\n",
      " --------------------\n",
      "Loss: 0.018137283623218536 | 0/938\n",
      "Loss: 0.021727019920945168 | 100/938\n",
      "Loss: 0.028860870748758316 | 200/938\n",
      "Loss: 0.016848431900143623 | 300/938\n",
      "Loss: 0.010056457482278347 | 400/938\n",
      "Loss: 0.017633572220802307 | 500/938\n",
      "Loss: 0.011128687299787998 | 600/938\n",
      "Loss: 0.021416189149022102 | 700/938\n",
      "Loss: 0.04554897919297218 | 800/938\n",
      "Loss: 0.02506745047867298 | 900/938\n",
      "\n",
      " Epoch: 76\n",
      " --------------------\n",
      "Loss: 0.01791476085782051 | 0/938\n",
      "Loss: 0.02112317457795143 | 100/938\n",
      "Loss: 0.028411924839019775 | 200/938\n",
      "Loss: 0.016705142334103584 | 300/938\n",
      "Loss: 0.009905585087835789 | 400/938\n",
      "Loss: 0.01704382337629795 | 500/938\n",
      "Loss: 0.01073831133544445 | 600/938\n",
      "Loss: 0.02072436548769474 | 700/938\n",
      "Loss: 0.04403925687074661 | 800/938\n",
      "Loss: 0.02386702224612236 | 900/938\n",
      "\n",
      " Epoch: 77\n",
      " --------------------\n",
      "Loss: 0.017779391258955002 | 0/938\n",
      "Loss: 0.020373158156871796 | 100/938\n",
      "Loss: 0.02788027562201023 | 200/938\n",
      "Loss: 0.016651062294840813 | 300/938\n",
      "Loss: 0.009719030931591988 | 400/938\n",
      "Loss: 0.016488704830408096 | 500/938\n",
      "Loss: 0.010388802736997604 | 600/938\n",
      "Loss: 0.020156200975179672 | 700/938\n",
      "Loss: 0.04306195676326752 | 800/938\n",
      "Loss: 0.022787684574723244 | 900/938\n",
      "\n",
      " Epoch: 78\n",
      " --------------------\n",
      "Loss: 0.017568198963999748 | 0/938\n",
      "Loss: 0.019517362117767334 | 100/938\n",
      "Loss: 0.02748074010014534 | 200/938\n",
      "Loss: 0.016391001641750336 | 300/938\n",
      "Loss: 0.009513640776276588 | 400/938\n",
      "Loss: 0.015979399904608727 | 500/938\n",
      "Loss: 0.010038673877716064 | 600/938\n",
      "Loss: 0.019620949402451515 | 700/938\n",
      "Loss: 0.04182044789195061 | 800/938\n",
      "Loss: 0.021741360425949097 | 900/938\n",
      "\n",
      " Epoch: 79\n",
      " --------------------\n",
      "Loss: 0.017199117690324783 | 0/938\n",
      "Loss: 0.01891764998435974 | 100/938\n",
      "Loss: 0.027035575360059738 | 200/938\n",
      "Loss: 0.016274143010377884 | 300/938\n",
      "Loss: 0.009370118379592896 | 400/938\n",
      "Loss: 0.015464444644749165 | 500/938\n",
      "Loss: 0.009763166308403015 | 600/938\n",
      "Loss: 0.01908460631966591 | 700/938\n",
      "Loss: 0.04086415469646454 | 800/938\n",
      "Loss: 0.020858710631728172 | 900/938\n",
      "\n",
      " Epoch: 80\n",
      " --------------------\n",
      "Loss: 0.01715839095413685 | 0/938\n",
      "Loss: 0.01835012063384056 | 100/938\n",
      "Loss: 0.026525776833295822 | 200/938\n",
      "Loss: 0.016036592423915863 | 300/938\n",
      "Loss: 0.009154065512120724 | 400/938\n",
      "Loss: 0.015047664754092693 | 500/938\n",
      "Loss: 0.009475033730268478 | 600/938\n",
      "Loss: 0.018531829118728638 | 700/938\n",
      "Loss: 0.03966469317674637 | 800/938\n",
      "Loss: 0.019926676526665688 | 900/938\n",
      "\n",
      " Epoch: 81\n",
      " --------------------\n",
      "Loss: 0.01694066822528839 | 0/938\n",
      "Loss: 0.01773875579237938 | 100/938\n",
      "Loss: 0.02591405063867569 | 200/938\n",
      "Loss: 0.01591222919523716 | 300/938\n",
      "Loss: 0.00900783110409975 | 400/938\n",
      "Loss: 0.014597482047975063 | 500/938\n",
      "Loss: 0.009166563861072063 | 600/938\n",
      "Loss: 0.018086375668644905 | 700/938\n",
      "Loss: 0.0387553796172142 | 800/938\n",
      "Loss: 0.019177652895450592 | 900/938\n",
      "\n",
      " Epoch: 82\n",
      " --------------------\n",
      "Loss: 0.01671091467142105 | 0/938\n",
      "Loss: 0.017193125560879707 | 100/938\n",
      "Loss: 0.025512007996439934 | 200/938\n",
      "Loss: 0.01577567495405674 | 300/938\n",
      "Loss: 0.008751828223466873 | 400/938\n",
      "Loss: 0.014089013449847698 | 500/938\n",
      "Loss: 0.008915023878216743 | 600/938\n",
      "Loss: 0.01764039322733879 | 700/938\n",
      "Loss: 0.0376313216984272 | 800/938\n",
      "Loss: 0.018440663814544678 | 900/938\n",
      "\n",
      " Epoch: 83\n",
      " --------------------\n",
      "Loss: 0.016613908112049103 | 0/938\n",
      "Loss: 0.016689414158463478 | 100/938\n",
      "Loss: 0.02498621866106987 | 200/938\n",
      "Loss: 0.015622539445757866 | 300/938\n",
      "Loss: 0.008596782572567463 | 400/938\n",
      "Loss: 0.013740096241235733 | 500/938\n",
      "Loss: 0.008657029829919338 | 600/938\n",
      "Loss: 0.01709427498281002 | 700/938\n",
      "Loss: 0.03677200525999069 | 800/938\n",
      "Loss: 0.017594346776604652 | 900/938\n",
      "\n",
      " Epoch: 84\n",
      " --------------------\n",
      "Loss: 0.016377761960029602 | 0/938\n",
      "Loss: 0.016118304803967476 | 100/938\n",
      "Loss: 0.0244687981903553 | 200/938\n",
      "Loss: 0.01550261490046978 | 300/938\n",
      "Loss: 0.008388573303818703 | 400/938\n",
      "Loss: 0.013354015536606312 | 500/938\n",
      "Loss: 0.008473263122141361 | 600/938\n",
      "Loss: 0.01673731952905655 | 700/938\n",
      "Loss: 0.03540325164794922 | 800/938\n",
      "Loss: 0.016870975494384766 | 900/938\n",
      "\n",
      " Epoch: 85\n",
      " --------------------\n",
      "Loss: 0.016153765842318535 | 0/938\n",
      "Loss: 0.015586256980895996 | 100/938\n",
      "Loss: 0.024022966623306274 | 200/938\n",
      "Loss: 0.01528928056359291 | 300/938\n",
      "Loss: 0.00825541839003563 | 400/938\n",
      "Loss: 0.012934645637869835 | 500/938\n",
      "Loss: 0.008234954439103603 | 600/938\n",
      "Loss: 0.01634705439209938 | 700/938\n",
      "Loss: 0.03478140011429787 | 800/938\n",
      "Loss: 0.016269605606794357 | 900/938\n",
      "\n",
      " Epoch: 86\n",
      " --------------------\n",
      "Loss: 0.01586173288524151 | 0/938\n",
      "Loss: 0.015279271639883518 | 100/938\n",
      "Loss: 0.023403886705636978 | 200/938\n",
      "Loss: 0.015207532793283463 | 300/938\n",
      "Loss: 0.008089479058980942 | 400/938\n",
      "Loss: 0.01259214524179697 | 500/938\n",
      "Loss: 0.007982786744832993 | 600/938\n",
      "Loss: 0.015922769904136658 | 700/938\n",
      "Loss: 0.03370816633105278 | 800/938\n",
      "Loss: 0.0156503114849329 | 900/938\n",
      "\n",
      " Epoch: 87\n",
      " --------------------\n",
      "Loss: 0.01573783904314041 | 0/938\n",
      "Loss: 0.014772039838135242 | 100/938\n",
      "Loss: 0.022972244769334793 | 200/938\n",
      "Loss: 0.015034446492791176 | 300/938\n",
      "Loss: 0.007951335050165653 | 400/938\n",
      "Loss: 0.012218017131090164 | 500/938\n",
      "Loss: 0.007802637759596109 | 600/938\n",
      "Loss: 0.015529142692685127 | 700/938\n",
      "Loss: 0.03266960382461548 | 800/938\n",
      "Loss: 0.01505281962454319 | 900/938\n",
      "\n",
      " Epoch: 88\n",
      " --------------------\n",
      "Loss: 0.015418934635818005 | 0/938\n",
      "Loss: 0.01449100486934185 | 100/938\n",
      "Loss: 0.022552885115146637 | 200/938\n",
      "Loss: 0.014870304614305496 | 300/938\n",
      "Loss: 0.007768030744045973 | 400/938\n",
      "Loss: 0.011898976750671864 | 500/938\n",
      "Loss: 0.007576059550046921 | 600/938\n",
      "Loss: 0.015155605040490627 | 700/938\n",
      "Loss: 0.03173132985830307 | 800/938\n",
      "Loss: 0.014520121738314629 | 900/938\n",
      "\n",
      " Epoch: 89\n",
      " --------------------\n",
      "Loss: 0.015480908565223217 | 0/938\n",
      "Loss: 0.014047225937247276 | 100/938\n",
      "Loss: 0.02208895795047283 | 200/938\n",
      "Loss: 0.014679787680506706 | 300/938\n",
      "Loss: 0.007616006303578615 | 400/938\n",
      "Loss: 0.011516427621245384 | 500/938\n",
      "Loss: 0.007439436856657267 | 600/938\n",
      "Loss: 0.014754299074411392 | 700/938\n",
      "Loss: 0.030949292704463005 | 800/938\n",
      "Loss: 0.013999790884554386 | 900/938\n",
      "\n",
      " Epoch: 90\n",
      " --------------------\n",
      "Loss: 0.015019704587757587 | 0/938\n",
      "Loss: 0.013769787736237049 | 100/938\n",
      "Loss: 0.02160695008933544 | 200/938\n",
      "Loss: 0.014461496844887733 | 300/938\n",
      "Loss: 0.007497264537960291 | 400/938\n",
      "Loss: 0.011188162490725517 | 500/938\n",
      "Loss: 0.007229333743453026 | 600/938\n",
      "Loss: 0.01444723829627037 | 700/938\n",
      "Loss: 0.029919615015387535 | 800/938\n",
      "Loss: 0.013468184508383274 | 900/938\n",
      "\n",
      " Epoch: 91\n",
      " --------------------\n",
      "Loss: 0.01495540700852871 | 0/938\n",
      "Loss: 0.013314791955053806 | 100/938\n",
      "Loss: 0.02122395671904087 | 200/938\n",
      "Loss: 0.014398543164134026 | 300/938\n",
      "Loss: 0.0073480261489748955 | 400/938\n",
      "Loss: 0.010913651436567307 | 500/938\n",
      "Loss: 0.007056324742734432 | 600/938\n",
      "Loss: 0.014079900458455086 | 700/938\n",
      "Loss: 0.029101334512233734 | 800/938\n",
      "Loss: 0.013057700358331203 | 900/938\n",
      "\n",
      " Epoch: 92\n",
      " --------------------\n",
      "Loss: 0.014776045456528664 | 0/938\n",
      "Loss: 0.013008841313421726 | 100/938\n",
      "Loss: 0.020839553326368332 | 200/938\n",
      "Loss: 0.014142537489533424 | 300/938\n",
      "Loss: 0.007232112810015678 | 400/938\n",
      "Loss: 0.010656691156327724 | 500/938\n",
      "Loss: 0.006880579516291618 | 600/938\n",
      "Loss: 0.013768266886472702 | 700/938\n",
      "Loss: 0.028257988393306732 | 800/938\n",
      "Loss: 0.012564193457365036 | 900/938\n",
      "\n",
      " Epoch: 93\n",
      " --------------------\n",
      "Loss: 0.014545554295182228 | 0/938\n",
      "Loss: 0.012669033370912075 | 100/938\n",
      "Loss: 0.020408708602190018 | 200/938\n",
      "Loss: 0.014065382070839405 | 300/938\n",
      "Loss: 0.007085203193128109 | 400/938\n",
      "Loss: 0.01035287231206894 | 500/938\n",
      "Loss: 0.006711562629789114 | 600/938\n",
      "Loss: 0.013442352414131165 | 700/938\n",
      "Loss: 0.02738128788769245 | 800/938\n",
      "Loss: 0.012140809558331966 | 900/938\n",
      "\n",
      " Epoch: 94\n",
      " --------------------\n",
      "Loss: 0.014375308528542519 | 0/938\n",
      "Loss: 0.012345203198492527 | 100/938\n",
      "Loss: 0.019994938746094704 | 200/938\n",
      "Loss: 0.013878993690013885 | 300/938\n",
      "Loss: 0.006965685170143843 | 400/938\n",
      "Loss: 0.010081682354211807 | 500/938\n",
      "Loss: 0.006574555765837431 | 600/938\n",
      "Loss: 0.013111814856529236 | 700/938\n",
      "Loss: 0.026567792519927025 | 800/938\n",
      "Loss: 0.011828784830868244 | 900/938\n",
      "\n",
      " Epoch: 95\n",
      " --------------------\n",
      "Loss: 0.014065545052289963 | 0/938\n",
      "Loss: 0.012041622772812843 | 100/938\n",
      "Loss: 0.019577139988541603 | 200/938\n",
      "Loss: 0.013704183511435986 | 300/938\n",
      "Loss: 0.006862340494990349 | 400/938\n",
      "Loss: 0.009818734601140022 | 500/938\n",
      "Loss: 0.006406696513295174 | 600/938\n",
      "Loss: 0.012869092635810375 | 700/938\n",
      "Loss: 0.025669069960713387 | 800/938\n",
      "Loss: 0.011428369209170341 | 900/938\n",
      "\n",
      " Epoch: 96\n",
      " --------------------\n",
      "Loss: 0.014006931334733963 | 0/938\n",
      "Loss: 0.011771379970014095 | 100/938\n",
      "Loss: 0.019212722778320312 | 200/938\n",
      "Loss: 0.013604659587144852 | 300/938\n",
      "Loss: 0.006713151931762695 | 400/938\n",
      "Loss: 0.009551852941513062 | 500/938\n",
      "Loss: 0.006262541748583317 | 600/938\n",
      "Loss: 0.012551817111670971 | 700/938\n",
      "Loss: 0.02501637302339077 | 800/938\n",
      "Loss: 0.011080492287874222 | 900/938\n",
      "\n",
      " Epoch: 97\n",
      " --------------------\n",
      "Loss: 0.013721595518290997 | 0/938\n",
      "Loss: 0.01145974826067686 | 100/938\n",
      "Loss: 0.018720388412475586 | 200/938\n",
      "Loss: 0.013416899368166924 | 300/938\n",
      "Loss: 0.00666614156216383 | 400/938\n",
      "Loss: 0.009383884258568287 | 500/938\n",
      "Loss: 0.006119866389781237 | 600/938\n",
      "Loss: 0.012232191860675812 | 700/938\n",
      "Loss: 0.024358853697776794 | 800/938\n",
      "Loss: 0.010708172805607319 | 900/938\n",
      "\n",
      " Epoch: 98\n",
      " --------------------\n",
      "Loss: 0.013589912094175816 | 0/938\n",
      "Loss: 0.011154120787978172 | 100/938\n",
      "Loss: 0.018423404544591904 | 200/938\n",
      "Loss: 0.01328457985073328 | 300/938\n",
      "Loss: 0.006503678858280182 | 400/938\n",
      "Loss: 0.009085902944207191 | 500/938\n",
      "Loss: 0.005924437195062637 | 600/938\n",
      "Loss: 0.012002539820969105 | 700/938\n",
      "Loss: 0.02347584441304207 | 800/938\n",
      "Loss: 0.010373464785516262 | 900/938\n",
      "\n",
      " Epoch: 99\n",
      " --------------------\n",
      "Loss: 0.0133871054276824 | 0/938\n",
      "Loss: 0.010956378653645515 | 100/938\n",
      "Loss: 0.018048131838440895 | 200/938\n",
      "Loss: 0.01318737305700779 | 300/938\n",
      "Loss: 0.006415702402591705 | 400/938\n",
      "Loss: 0.008894908241927624 | 500/938\n",
      "Loss: 0.0058249859139323235 | 600/938\n",
      "Loss: 0.011702208779752254 | 700/938\n",
      "Loss: 0.022709492594003677 | 800/938\n",
      "Loss: 0.010060007683932781 | 900/938\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, dataloader, loss_fn, optimiser):\n",
    "    for batch_no, batch in enumerate(dataloader):\n",
    "        # Define our images and labels for this batch\n",
    "        images = batch[0]\n",
    "        labels = batch[1]\n",
    "\n",
    "        # Forward pass and Calculate loss\n",
    "        pred = model(images)\n",
    "        loss = loss_fn(pred, labels)\n",
    "\n",
    "        # Back prop and zero grad\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Update our parameters\n",
    "        optimiser.step()\n",
    "\n",
    "        if batch_no % 100 == 0:\n",
    "            print(f\"Loss: {loss} | {batch_no}/{len(dataloader)}\")\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n Epoch: {epoch}\\n --------------------\")\n",
    "    train_model(model, train_dataloader, loss_fn, optimiser)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test our trained Model on a single image its never seen before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0004236992390360683\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = None\n",
    "label = None\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    img = batch[0][10]\n",
    "    label = batch[1][10]\n",
    "    # break\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(img)\n",
    "    loss = loss_fn(pred.squeeze(), label)\n",
    "\n",
    "index = torch.where(label == 1)[0].item()\n",
    "print(f\"Test Loss: {loss}\")\n",
    "\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.title(f\"Label: {index} | Prediction: {torch.argmax(pred)}\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate our model's performance on a complete test dataset\n",
    "\n",
    "We want to feed our model on brand new data and see how accurate it's predictions are\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.065301 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            images = batch[0]\n",
    "            labels = batch[1]\n",
    "            pred = model(images)\n",
    "            test_loss += loss_fn(pred, labels).item()\n",
    "            pred = np.array([torch.argmax(pred_label) for pred_label in pred])\n",
    "            labels = np.array([torch.argmax(label) for label in labels])\n",
    "            correct += (pred == labels).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(\n",
    "        f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "test_loop(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save our model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./DigiNet.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch_AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
